{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8: Build a pipeline using Amazon SagerMaker Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final notebook, you will build a model build workflow that orchestrates the preprocessing and training steps and registers the serial inference pipeline model in the SageMaker Model Registry. You will use Amazon SageMaker Pipelines for the workflow orchestration and lineage.\n",
    "\n",
    "Orchestrating and automating the model build workflow is preliminary to any ML CI/CD, since CI/CD automations must be capable of executing the steps that lead to the generation of a model, which can vary based on the use case. The idea is that a typical \"build\" stage of CI/CD will execute a workflow that has been previously defined by a Data Scientist.\n",
    "\n",
    "Amazon SageMaker Pipelines  supports a pipeline Domain Specific Language (DSL), which is a declarative JSON specification. This DSL defines a Directed Acyclic Graph (DAG) of pipeline parameters and steps. The SageMaker Python SDK streamlines the generation of the pipeline DSL using constructs that are already familiar to engineers and scientists alike.\n",
    "\n",
    "SageMaker Model Registry is where trained models are stored, versioned, and managed. Data Scientists and Machine Learning Engineers can compare model versions, approve models for deployment, and deploy models from different AWS accounts, all from a single Model Registry.\n",
    "\n",
    "Let's define the variables first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "prefix = 'end-to-end-ml'\n",
    "\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r experiment_name\n",
    "\n",
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Define Pipeline</h2>\n",
    "\n",
    "In this section, you will define a model build workflow for the pre-processing and training operations you executed manually in the previous notebooks. The workflow definition will also include steps to register the model in the SageMaker model registry.\n",
    "\n",
    "Your objective is defining a pipeline as shown below: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Workflow](./workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline will execute the following steps:\n",
    "- Run a SageMaker Processing job to execute data preparation and generate a featurizer model\n",
    "    - Repack the featurizer model to bundle inference scripts\n",
    "- Run a SageMAker Training job to train the XGBoost model\n",
    "    - Repack the XGBoost model to bundle inference scripts\n",
    "- Register a serial inference pipeline of the two models in the SageMaker Model Registry\n",
    "\n",
    "Note: SageMaker automatically adds the model repack steps to convert the models to a format suitable for inference when custom inference logic is required. You will not add these steps explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pipeline parameters</h3>\n",
    "\n",
    "You define workflow parameters for the pipeline so that you can vary the values without having to modify the workflow definition.\n",
    "\n",
    "The supported parameter types include:\n",
    "\n",
    "* `ParameterString` - representing a `str` Python type\n",
    "* `ParameterInteger` - representing an `int` Python type\n",
    "* `ParameterFloat` - representing a `float` Python type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat,\n",
    ")\n",
    "\n",
    "# ---------------------\n",
    "# Processing parameters\n",
    "# ---------------------\n",
    "\n",
    "# The path to the raw data.\n",
    "raw_data_path = 's3://{0}/{1}/data/raw/'.format(bucket_name, prefix)\n",
    "raw_data_path_param = ParameterString(name=\"raw_data_path\", default_value=raw_data_path)\n",
    "\n",
    "# The output path to the training data.\n",
    "train_data_path = 's3://{0}/{1}/data/preprocessed/train/'.format(bucket_name, prefix)\n",
    "train_data_path_param = ParameterString(name=\"train_data_path\", default_value=train_data_path)\n",
    "\n",
    "# The output path to the validation data.\n",
    "val_data_path = 's3://{0}/{1}/data/preprocessed/val/'.format(bucket_name, prefix)\n",
    "val_data_path_param = ParameterString(name=\"val_data_path\", default_value=val_data_path)\n",
    "\n",
    "# The output path to the test data.\n",
    "test_data_path = 's3://{0}/{1}/data/preprocessed/test/'.format(bucket_name, prefix)\n",
    "test_data_path_param = ParameterString(name=\"test_data_path\", default_value=test_data_path)\n",
    "\n",
    "# The output path to the featurizer model.\n",
    "model_path = 's3://{0}/{1}/output/sklearn/model.tar.gz'.format(bucket_name, prefix)\n",
    "model_path_param = ParameterString(name=\"model_path\", default_value=model_path)\n",
    "\n",
    "# The instance type for the processing job.\n",
    "processing_instance_type_param = ParameterString(name=\"processing_instance_type\", default_value='ml.m5.large')\n",
    "\n",
    "# The instance count for the processing job.\n",
    "processing_instance_count_param = ParameterInteger(name=\"processing_instance_count\", default_value=1)\n",
    "\n",
    "# The train/test split ration parameter.\n",
    "train_test_split_ratio_param = ParameterString(name=\"train_test_split_ratio\", default_value='0.2')\n",
    "\n",
    "# -------------------\n",
    "# Training parameters\n",
    "# -------------------\n",
    "        \n",
    "# XGB hyperparameters.\n",
    "max_depth_param = ParameterString(name=\"max_depth\", default_value='3')\n",
    "eta_param = ParameterString(name=\"eta\", default_value='0.1')\n",
    "gamma_param = ParameterString(name=\"gamma\", default_value='0')\n",
    "min_child_weight_param = ParameterString(name=\"min_child_weight\", default_value='1')\n",
    "objective_param = ParameterString(name=\"objective\", default_value='binary:logistic')\n",
    "num_round_param = ParameterString(name=\"num_round\", default_value='10')\n",
    "eval_metric_param = ParameterString(name=\"eval_metric\", default_value='auc')\n",
    "\n",
    "# The instance type for the training job.\n",
    "training_instance_type_param = ParameterString(name=\"training_instance_type\", default_value='ml.m5.xlarge')\n",
    "\n",
    "# The instance count for the training job.\n",
    "training_instance_count_param = ParameterInteger(name=\"training_instance_count\", default_value=1)\n",
    "\n",
    "# The training output path for the model.\n",
    "output_path = 's3://{0}/{1}/output/'.format(bucket_name, prefix)\n",
    "output_path_param = ParameterString(name=\"output_path\", default_value=output_path)\n",
    "\n",
    "# --------------------------\n",
    "# Register model parameters\n",
    "# --------------------------\n",
    "\n",
    "# The default intance type for deployment.\n",
    "deploy_instance_type_param = ParameterString(name=\"deploy_instance_type\", default_value='ml.m5.2xlarge')\n",
    "\n",
    "# The approval status for models added to the registry.\n",
    "model_approval_status_param = ParameterString(name=\"model_approval_status\", default_value='PendingManualApproval')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Processing Step</h3>\n",
    "\n",
    "Now, you define the processing step that will prepare the dataset, as seen in module <a href=\"../03_feature_Engineering/03_feature_engineering.ipynb\">03_feature_engineering</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pygmentize ../03_feature_engineering/source_dir/preprocessor.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(role=role,\n",
    "                                     instance_type=processing_instance_type_param,\n",
    "                                     instance_count=processing_instance_count_param,\n",
    "                                     framework_version='0.20.0')\n",
    "\n",
    "inputs = [ProcessingInput(input_name='raw_data', \n",
    "                          source=raw_data_path_param, destination='/opt/ml/processing/input')]\n",
    "\n",
    "outputs = [ProcessingOutput(output_name='train_data', \n",
    "                            source='/opt/ml/processing/train', destination=train_data_path_param),\n",
    "           ProcessingOutput(output_name='val_data', \n",
    "                            source='/opt/ml/processing/val', destination=val_data_path_param),\n",
    "           ProcessingOutput(output_name='test_data', \n",
    "                            source='/opt/ml/processing/test', destination=test_data_path_param),\n",
    "           ProcessingOutput(output_name='model', \n",
    "                            source='/opt/ml/processing/model', destination=model_path_param)]\n",
    "\n",
    "code_path = '../03_feature_engineering/source_dir/preprocessor.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "processing_step = ProcessingStep(\n",
    "    name='Processing', \n",
    "    code=code_path,\n",
    "    processor=sklearn_processor,\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    job_arguments=['--train-test-split-ratio', train_test_split_ratio_param]\n",
    ")\n",
    "\n",
    "print(processing_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training Step</h3>\n",
    "\n",
    "Then, we create a training step, using the same estimator definition as seen in module <a href=\"../04_train_model/04_train_model.ipynb\">04_train_model</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pygmentize ../04_train_model/source_dir/training.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.xgboost import XGBoost\n",
    "\n",
    "hyperparameters = {\n",
    "    \"max_depth\": max_depth_param,\n",
    "    \"eta\": eta_param,\n",
    "    \"gamma\": gamma_param,\n",
    "    \"min_child_weight\": min_child_weight_param,\n",
    "    \"silent\": 0,\n",
    "    \"objective\": objective_param,\n",
    "    \"num_round\": num_round_param,\n",
    "    \"eval_metric\": eval_metric_param\n",
    "}\n",
    "\n",
    "entry_point='training.py'\n",
    "source_dir='../04_train_model/source_dir/'\n",
    "code_location = 's3://{0}/{1}/code'.format(bucket_name, prefix)\n",
    "\n",
    "estimator = XGBoost(\n",
    "    entry_point=entry_point,\n",
    "    source_dir=source_dir,\n",
    "    output_path=output_path_param,\n",
    "    code_location=code_location,\n",
    "    hyperparameters=hyperparameters,\n",
    "    instance_type=training_instance_type_param,\n",
    "    instance_count=training_instance_count_param,\n",
    "    framework_version=\"0.90-2\",\n",
    "    py_version=\"py3\",\n",
    "    role=role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "training_step = TrainingStep(\n",
    "    name='Training',\n",
    "    estimator=estimator,\n",
    "    inputs={\n",
    "        'train': TrainingInput(\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'train_data'\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type='text/csv'\n",
    "        ),\n",
    "        'validation': TrainingInput(\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'val_data'\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type='text/csv'\n",
    "        )      \n",
    "    }\n",
    ")\n",
    "\n",
    "print(training_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Register Model Step</h3>\n",
    "\n",
    "Last step to define is the step for registering the serial inference pipeline model into the SageMaker Model Registry. We create a PipelineModel as seen in <a href=\"../04_deploy_model/04_deploy_model.ipynb\">04_deploy_model</a> based on the SKLearn and XGBoost models, and then use it for the register model step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Featurizer Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.sklearn import SKLearnModel\n",
    "\n",
    "code_location = 's3://{0}/{1}/code'.format(bucket_name, prefix)\n",
    "\n",
    "sklearn_model = SKLearnModel(name='end-to-end-ml-sm-skl-model-{0}'.format(str(int(time.time()))),\n",
    "                             model_data=processing_step.properties.ProcessingOutputConfig.Outputs['model'].S3Output.S3Uri,\n",
    "                             entry_point='inference.py',\n",
    "                             source_dir='../05_deploy_model/sklearn_source_dir/',\n",
    "                             code_location=code_location,\n",
    "                             role=role,\n",
    "                             sagemaker_session=sagemaker_session,\n",
    "                             framework_version='0.20.0',\n",
    "                             py_version='py3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>XGBoost Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.xgboost import XGBoostModel\n",
    "\n",
    "code_location = 's3://{0}/{1}/code'.format(bucket_name, prefix)\n",
    "\n",
    "xgboost_model = XGBoostModel(name='end-to-end-ml-sm-xgb-model-{0}'.format(str(int(time.time()))),\n",
    "                             model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "                             entry_point='inference.py',\n",
    "                             source_dir='../05_deploy_model/xgboost_source_dir/',\n",
    "                             code_location=code_location,\n",
    "                             framework_version='0.90-2',\n",
    "                             py_version='py3',\n",
    "                             role=role, \n",
    "                             sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Serial Inference Pipeline Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import time\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "\n",
    "pipeline_model_name = 'end-to-end-ml-sm-xgb-skl-pipeline-{0}'.format(str(int(time.time())))\n",
    "\n",
    "pipeline_model = PipelineModel(\n",
    "    name=pipeline_model_name, \n",
    "    role=role,\n",
    "    models=[\n",
    "        sklearn_model, \n",
    "        xgboost_model],\n",
    "    sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Register Model Step</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "model_package_group_name = 'end-to-end-ml-sm-model-package-group'\n",
    "\n",
    "register_model_step = RegisterModel(\n",
    "    name='RegisterModel',\n",
    "    content_types=['text/csv'],\n",
    "    response_types=['application/json', 'text/csv'],\n",
    "    inference_instances=[deploy_instance_type_param],\n",
    "    transform_instances=['ml.c5.4xlarge'],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status_param,\n",
    "    model = pipeline_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pipeline</h3>\n",
    "\n",
    "After all steps have been defined, we are now ready to create our model build workflow (SageMaker Pipeline).\n",
    "The pipeline definition takes as input all parameters we have previously created, and the sequence of steps. In this example, the dependencies among the steps will be automatically computed based on the inputs and outputs of each step, but the service supports also setting them explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = 'end-to-end-ml-sagemaker-pipeline'\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        raw_data_path_param,\n",
    "        train_data_path_param,\n",
    "        val_data_path_param,\n",
    "        test_data_path_param,\n",
    "        model_path_param,\n",
    "        processing_instance_type_param,\n",
    "        processing_instance_count_param,\n",
    "        train_test_split_ratio_param,\n",
    "        max_depth_param,\n",
    "        eta_param,\n",
    "        gamma_param,\n",
    "        min_child_weight_param,\n",
    "        objective_param,\n",
    "        num_round_param,\n",
    "        eval_metric_param,\n",
    "        training_instance_type_param,\n",
    "        training_instance_count_param,\n",
    "        output_path_param,\n",
    "        deploy_instance_type_param,\n",
    "        model_approval_status_param\n",
    "    ],\n",
    "    steps=[processing_step, training_step, register_model_step],\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a look at the JSON representation of the pipeline as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "definition = json.loads(pipeline.definition())\n",
    "definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Insert and Execute the pipeline</h2>\n",
    "\n",
    "Once the pipeline has been defined, we have to insert/update its definition on the service, and then we can start it, providing the parameters (for the ones not set, the default value will be used at run-time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pipeline.upsert(role_arn=role)\n",
    "\n",
    "pipeline_arn = response[\"PipelineArn\"]\n",
    "print(pipeline_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.experiments.run import Run\n",
    "\n",
    "run_name=f'pipeline-{time.strftime(\"%H-%M-%S\", time.localtime())}'\n",
    "run_display_name=run_name\n",
    "\n",
    "with Run(\n",
    "    experiment_name=experiment_name,\n",
    "    run_name=run_name,\n",
    "    run_display_name=run_display_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "\n",
    "    execution = pipeline.start(parameters={\n",
    "        'train_test_split_ratio': '0.2'\n",
    "    })\n",
    "    print(execution.arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Wait for pipeline execution</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While waiting for pipeline execution to complete (it will take ~10mins), feel free to use the left side panel in SageMaker Studio to review the pipeline definition and execution status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Approve model in the SageMaker Model Registry</h2>\n",
    "\n",
    "When the pipeline has completed its execution, the model has been registered to the model registry with a PendingManualApproval status and we need to approve it before deployment.\n",
    "\n",
    "First, we get the ARN (Amazon Resource Name) of the versioned model package (i.e. versioned model in the model registry)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = execution.list_steps()\n",
    "\n",
    "register_model_step = next(s for s in steps if s['StepName'].startswith('RegisterModel') )\n",
    "\n",
    "model_package_arn = register_model_step['Metadata']['RegisterModel']['Arn']\n",
    "print(model_package_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's describe the model package and check the InferenceSpecification property to make sure the serial inference pipeline of models has been set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "response = sm_client.describe_model_package(\n",
    "    ModelPackageName=model_package_arn)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can approve the model package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.update_model_package(\n",
    "    ModelPackageArn=model_package_arn,\n",
    "    ModelApprovalStatus=\"Approved\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Deploy real-time endpoint from the model package in the registry</h2>\n",
    "\n",
    "In order to deploy the model from the model registry, we can use the ModelPackage class of the SDK as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import ModelPackage\n",
    "\n",
    "model_package = ModelPackage(model_package_arn=model_package_arn,\n",
    "                             role=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'end-to-end-ml-sm-pipeline-endpoint-{0}'.format(str(int(time.time())))\n",
    "print(endpoint_name)\n",
    "\n",
    "model_package.deploy(initial_instance_count=1, \n",
    "                     instance_type='ml.m5.2xlarge', \n",
    "                     endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Execute inference</h3>\n",
    "\n",
    "Let's execute some inferences to test our real-time endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=CSVSerializer(),\n",
    "    deserializer=JSONDeserializer())\n",
    "\n",
    "payload = \"L,298.4,308.2,1582,70.7,216\"\n",
    "print(predictor.predict(payload))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can cleanup resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You have completed Module 8 and the workshop!\n",
    "\n",
    "Well done! \n",
    "\n",
    "We hope you have seen the journey that started with experimentation in SageMaker Studio Notebook, through to preprocessing and training jobs, onto model deployment and inference, and ending with building a pipeline for running the preprocessing and building steps.\n",
    "\n",
    "Please feel free to contiunue exploring SageMaker Studio environment and reading the notes in the notebooks you might have skipped when going through the workshop.\n",
    "\n",
    "### Clean up\n",
    "\n",
    "If you are attending an AWS-led event, there is no need for a clean up. However, if you have been using your AWS environment, please follow the [clean up steps](../cleanup/README.md) to avoid incurring charges."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
