{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Training</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use the Amazon SageMaker open source XGBoost container (https://github.com/aws/sagemaker-xgboost-container) to train a simple binary classification model, using the pre-processed data generated in the previous step by the processing job.\n",
    "Using XGBoost as a framework provides more flexibility than using it as a built-in algorithm as it enables more advanced scenarios that allow pre-processing and post-processing scripts or any kind of custom logic to be incorporated into your training script.\n",
    "\n",
    "Let's define the variables first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/end-to-end-ml-sm/03_train_model\n"
     ]
    }
   ],
   "source": [
    "# When using Amazon SageMaker Studio, please set this variable to True and execute the cell\n",
    "use_sm_studio = True\n",
    "if use_sm_studio:\n",
    "    %cd /root/end-to-end-ml-sm/03_train_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.23.5\n"
     ]
    }
   ],
   "source": [
    "# Check SageMaker Python SDK version\n",
    "import sagemaker\n",
    "print(sagemaker.__version__)\n",
    "\n",
    "def versiontuple(v):\n",
    "    return tuple(map(int, (v.split(\".\"))))\n",
    "\n",
    "if versiontuple(sagemaker.__version__) < versiontuple('2.5.0'):\n",
    "    raise Exception(\"This notebook requires at least SageMaker Python SDK version 2.5.0. Please install it via pip.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n",
      "arn:aws:iam::041631420165:role/service-role/AmazonSageMaker-ExecutionRole-endtoendml\n",
      "sagemaker-us-east-1-041631420165\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "prefix = 'endtoendmlsm'\n",
    "\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end-to-end-ml-sagemaker-1612336463\n",
      "sklearn-xgboost-1612336478\n"
     ]
    }
   ],
   "source": [
    "%store -r experiment_name\n",
    "%store -r trial_name\n",
    "\n",
    "print(experiment_name)\n",
    "print(trial_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training code is implemented in the `source_dir/training.py` file.\n",
    "\n",
    "The script parses arguments that are passed when the XGBoost Docker container code invokes the script for execution. These arguments represent the hyperparameters that you specify when strarting the training job plus the location of training and validation data. Then, we load training and validation data and execute XGBoost training with the provided parameters.\n",
    "\n",
    "<strong>Note</strong>: this behavior, named Script Mode execution, is enabled by a library that is installed in the XGBoost container (sagemaker-containers, https://github.com/aws/sagemaker-containers) and facilitates the development of SageMaker-compatible Docker containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrandom\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mglob\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpkl\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mxgboost\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mparse_args\u001b[39;49;00m():\n",
      "\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--max_depth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m5\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--eta\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.05\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--gamma\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m4\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--min_child_weight\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m6\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--silent\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m0\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--objective\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m\"\u001b[39;49;00m\u001b[33mreg:logistic\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--num_round\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m)\n",
      "    \n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--validation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_VALIDATION\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m args\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain\u001b[39;49;00m():\n",
      "\n",
      "    args = parse_args()\n",
      "    train_files_path, validation_files_path = args.train, args.validation\n",
      "    \n",
      "    train_features_path = os.path.join(args.train, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_features.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    train_labels_path = os.path.join(args.train, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_labels.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \n",
      "    val_features_path = os.path.join(args.validation, \u001b[33m'\u001b[39;49;00m\u001b[33mval_features.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    val_labels_path = os.path.join(args.validation, \u001b[33m'\u001b[39;49;00m\u001b[33mval_labels.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mLoading training dataframes...\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    df_train_features = pd.read_csv(train_features_path)\n",
      "    df_train_labels = pd.read_csv(train_labels_path)\n",
      "    \n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mLoading validation dataframes...\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    df_val_features = pd.read_csv(val_features_path)\n",
      "    df_val_labels = pd.read_csv(val_labels_path)\n",
      "    \n",
      "    X = df_train_features.values\n",
      "    y = df_train_labels.values\n",
      "    \n",
      "    val_X = df_val_features.values\n",
      "    val_y = df_val_labels.values\n",
      "\n",
      "    dtrain = xgboost.DMatrix(X, label=y)\n",
      "    dval = xgboost.DMatrix(val_X, label=val_y)\n",
      "\n",
      "    watchlist = [(dtrain, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), (dval, \u001b[33m\"\u001b[39;49;00m\u001b[33mvalidation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)]\n",
      "\n",
      "    params = {\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mmax_depth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.max_depth,\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33meta\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.eta,\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mgamma\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.gamma,\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mmin_child_weight\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.min_child_weight,\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33msilent\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.silent,\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mobjective\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.objective\n",
      "    }\n",
      "\n",
      "    bst = xgboost.train(\n",
      "        params=params,\n",
      "        dtrain=dtrain,\n",
      "        evals=watchlist,\n",
      "        num_boost_round=args.num_round)\n",
      "    \n",
      "    model_dir = os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    pkl.dump(bst, \u001b[36mopen\u001b[39;49;00m(model_dir + \u001b[33m'\u001b[39;49;00m\u001b[33m/model.bin\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    main()\n"
     ]
    }
   ],
   "source": [
    "!pygmentize source_dir/training.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our script ready, we can leverage on the XGBoost estimator of the Amazon SageMaker Python SDK to start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.xgboost import XGBoost\n",
    "\n",
    "hyperparameters = {\n",
    "    \"max_depth\": \"3\",\n",
    "    \"eta\": \"0.1\",\n",
    "    \"gamma\": \"6\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"silent\": \"0\",\n",
    "    \"objective\": \"reg:logistic\",\n",
    "    \"num_round\": \"20\"\n",
    "}\n",
    "\n",
    "entry_point='training.py'\n",
    "source_dir='source_dir/'\n",
    "output_path = 's3://{0}/{1}/output/'.format(bucket_name, prefix)\n",
    "code_location = 's3://{0}/{1}/code'.format(bucket_name, prefix)\n",
    "\n",
    "estimator = XGBoost(\n",
    "    base_job_name=\"end-to-end-ml-sm-xgb\",\n",
    "    entry_point=entry_point,\n",
    "    source_dir=source_dir,\n",
    "    output_path=output_path,\n",
    "    code_location=code_location,\n",
    "    hyperparameters=hyperparameters,\n",
    "    instance_type=\"ml.m5.xlarge\", # Specify local as instance type to run local-mode training\n",
    "    instance_count=1,\n",
    "    framework_version=\"0.90-2\",\n",
    "    py_version=\"py3\",\n",
    "    role=role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-03 07:34:18 Starting - Starting the training job...\n",
      "2021-02-03 07:34:40 Starting - Launching requested ML instancesProfilerReport-1612337657: InProgress\n",
      "......\n",
      "2021-02-03 07:35:41 Starting - Preparing the instances for training......\n",
      "2021-02-03 07:36:42 Downloading - Downloading input data......\n",
      "2021-02-03 07:37:46 Training - Training image download completed. Training in progress..\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Invoking user training script.\u001b[0m\n",
      "\n",
      "2021-02-03 07:38:17 Uploading - Uploading generated training model\u001b[34mINFO:sagemaker-containers:Module training does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Generating setup.cfg\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: training\n",
      "  Building wheel for training (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for training (setup.py): finished with status 'done'\n",
      "  Created wheel for training: filename=training-1.0.0-py2.py3-none-any.whl size=7740 sha256=bbf066a611e4c4db9f8b7b5617764c599386ca53650071459eb7bdb340950bb7\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-2wslvaj_/wheels/95/c1/85/65aaf48b35aba88c6e896d2fd04a4b69f1cee0d81ea32993ca\u001b[0m\n",
      "\u001b[34mSuccessfully built training\u001b[0m\n",
      "\u001b[34mInstalling collected packages: training\u001b[0m\n",
      "\u001b[34mSuccessfully installed training-1.0.0\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"silent\": \"0\",\n",
      "        \"eta\": \"0.1\",\n",
      "        \"max_depth\": \"3\",\n",
      "        \"num_round\": \"20\",\n",
      "        \"gamma\": \"6\",\n",
      "        \"min_child_weight\": \"6\",\n",
      "        \"objective\": \"reg:logistic\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"end-to-end-ml-sm-xgb-2021-02-03-07-34-17-930\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-041631420165/endtoendmlsm/code/end-to-end-ml-sm-xgb-2021-02-03-07-34-17-930/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"training\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"training.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"eta\":\"0.1\",\"gamma\":\"6\",\"max_depth\":\"3\",\"min_child_weight\":\"6\",\"num_round\":\"20\",\"objective\":\"reg:logistic\",\"silent\":\"0\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=training.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=training\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-041631420165/endtoendmlsm/code/end-to-end-ml-sm-xgb-2021-02-03-07-34-17-930/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"eta\":\"0.1\",\"gamma\":\"6\",\"max_depth\":\"3\",\"min_child_weight\":\"6\",\"num_round\":\"20\",\"objective\":\"reg:logistic\",\"silent\":\"0\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"end-to-end-ml-sm-xgb-2021-02-03-07-34-17-930\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-041631420165/endtoendmlsm/code/end-to-end-ml-sm-xgb-2021-02-03-07-34-17-930/source/sourcedir.tar.gz\",\"module_name\":\"training\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"training.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--eta\",\"0.1\",\"--gamma\",\"6\",\"--max_depth\",\"3\",\"--min_child_weight\",\"6\",\"--num_round\",\"20\",\"--objective\",\"reg:logistic\",\"--silent\",\"0\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_SILENT=0\u001b[0m\n",
      "\u001b[34mSM_HP_ETA=0.1\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DEPTH=3\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_ROUND=20\u001b[0m\n",
      "\u001b[34mSM_HP_GAMMA=6\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_CHILD_WEIGHT=6\u001b[0m\n",
      "\u001b[34mSM_HP_OBJECTIVE=reg:logistic\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python3.6/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python36.zip:/miniconda3/lib/python3.6:/miniconda3/lib/python3.6/lib-dynload:/miniconda3/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m training --eta 0.1 --gamma 6 --max_depth 3 --min_child_weight 6 --num_round 20 --objective reg:logistic --silent 0\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mLoading training dataframes...\u001b[0m\n",
      "\u001b[34mLoading validation dataframes...\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.462232#011validation-rmse:0.461806\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.428596#011validation-rmse:0.428506\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.40035#011validation-rmse:0.399579\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.374372#011validation-rmse:0.37375\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.35075#011validation-rmse:0.350619\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:0.330889#011validation-rmse:0.330348\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:0.312676#011validation-rmse:0.312276\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.296167#011validation-rmse:0.295665\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.281362#011validation-rmse:0.280819\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.267819#011validation-rmse:0.267254\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.254787#011validation-rmse:0.254078\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:0.244323#011validation-rmse:0.243534\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:0.232952#011validation-rmse:0.232425\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:0.223058#011validation-rmse:0.222362\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:0.21358#011validation-rmse:0.21305\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:0.205165#011validation-rmse:0.204554\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:0.196301#011validation-rmse:0.195772\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:0.189117#011validation-rmse:0.188467\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:0.181345#011validation-rmse:0.180877\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:0.174484#011validation-rmse:0.173971\u001b[0m\n",
      "\n",
      "2021-02-03 07:38:44 Completed - Training job completed\n",
      "ProfilerReport-1612337657: NoIssuesFound\n",
      "Training seconds: 116\n",
      "Billable seconds: 116\n"
     ]
    }
   ],
   "source": [
    "# Experiment tracking configuration\n",
    "experiment_config={\n",
    "    \"ExperimentName\": experiment_name,\n",
    "    \"TrialName\": trial_name,\n",
    "    \"TrialComponentDisplayName\": \"xgboost-training\",\n",
    "}\n",
    "\n",
    "train_config = sagemaker.TrainingInput('s3://{0}/{1}/data/preprocessed/train/'.format(\n",
    "    bucket_name, prefix), content_type='text/csv')\n",
    "val_config = sagemaker.TrainingInput('s3://{0}/{1}/data/preprocessed/val/'.format(\n",
    "    bucket_name, prefix), content_type='text/csv')\n",
    "\n",
    "estimator.fit({'train': train_config, 'validation': val_config },\n",
    "              experiment_config=experiment_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment analytics\n",
    "\n",
    "You can visualize experiment analytics either from Amazon SageMaker Studio Experiments plug-in or using the SDK from a notebook, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "\n",
    "analytics = ExperimentAnalytics(experiment_name=experiment_name)\n",
    "analytics.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training is completed, the serialized model will be saved in the S3 `output_location` defined above.\n",
    "You can now move to the next notebook in the **04_deploy_model** folder to see how to use that model for inference."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
